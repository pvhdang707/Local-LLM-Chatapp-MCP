import uuid
import json
import pandas as pd
from typing import Dict, List, Optional, Any
from datetime import datetime
from langchain_ollama import ChatOllama
from src.config import OllamaConfig
from src.file_search import file_search_engine
from src.file_classifier import file_classifier
from src.cloud_integration import cloud_integration
from src.file_manager import file_manager
import os

class AgenticAI:
    def __init__(self):
        self.llm = ChatOllama(
            model=OllamaConfig.RagModel,
            temperature=0.1,
            base_url=OllamaConfig.Host,
        )
        
        # ƒê·ªãnh nghƒ©a c√°c action c√≥ th·ªÉ th·ª±c hi·ªán
        self.available_actions = {
            'search_files': {
                'name': 'T√¨m ki·∫øm file',
                'description': 'T√¨m ki·∫øm file theo t√™n ho·∫∑c n·ªôi dung',
                'parameters': ['query', 'search_type']
            },
            'classify_files': {
                'name': 'Ph√¢n lo·∫°i file',
                'description': 'Ph√¢n lo·∫°i file th√†nh c√°c nh√≥m',
                'parameters': ['file_ids']
            },
            'extract_metadata': {
                'name': 'Tr√≠ch xu·∫•t metadata',
                'description': 'Tr√≠ch xu·∫•t th√¥ng tin metadata t·ª´ file',
                'parameters': ['file_ids']
            },
            'export_metadata': {
                'name': 'Xu·∫•t metadata',
                'description': 'Xu·∫•t metadata ra file Excel',
                'parameters': ['file_ids', 'output_format']
            },
            'upload_to_cloud': {
                'name': 'Upload l√™n cloud',
                'description': 'G·ª≠i metadata l√™n cloud storage',
                'parameters': ['file_ids']
            }
        }
    
    def plan_actions(self, user_request: str) -> Dict:
        """L√™n k·∫ø ho·∫°ch h√†nh ƒë·ªông d·ª±a tr√™n y√™u c·∫ßu c·ªßa user"""
        try:
            # T·∫°o prompt ƒë·ªÉ AI l√™n k·∫ø ho·∫°ch
            prompt = f"""
            B·∫°n l√† m·ªôt AI Agent th√¥ng minh. D·ª±a tr√™n y√™u c·∫ßu c·ªßa user, h√£y l√™n k·∫ø ho·∫°ch c√°c h√†nh ƒë·ªông c·∫ßn th·ª±c hi·ªán.
            
            Y√™u c·∫ßu c·ªßa user: "{user_request}"
            
            C√°c h√†nh ƒë·ªông c√≥ th·ªÉ th·ª±c hi·ªán:
            {json.dumps(self.available_actions, indent=2, ensure_ascii=False)}
            
            H√£y ph√¢n t√≠ch y√™u c·∫ßu v√† tr·∫£ v·ªÅ k·∫ø ho·∫°ch h√†nh ƒë·ªông theo format JSON:
            {{
                "plan": [
                    {{
                        "action": "t√™n_h√†nh_ƒë·ªông",
                        "description": "M√¥ t·∫£ h√†nh ƒë·ªông",
                        "parameters": {{"param1": "value1"}},
                        "order": 1
                    }}
                ],
                "expected_output": "M√¥ t·∫£ k·∫øt qu·∫£ mong ƒë·ª£i",
                "estimated_steps": 3
            }}
            
            V√≠ d·ª• cho y√™u c·∫ßu "T√¨m file 'k·∫ø ho·∫°ch marketing 2024' v√† xu·∫•t danh s√°ch":
            {{
                "plan": [
                    {{
                        "action": "search_files",
                        "description": "T√¨m ki·∫øm file c√≥ ch·ª©a 'k·∫ø ho·∫°ch marketing 2024'",
                        "parameters": {{"query": "k·∫ø ho·∫°ch marketing 2024", "search_type": "both"}},
                        "order": 1
                    }},
                    {{
                        "action": "classify_files",
                        "description": "Ph√¢n lo·∫°i c√°c file t√¨m ƒë∆∞·ª£c",
                        "parameters": {{"file_ids": "dynamic"}},
                        "order": 2
                    }},
                    {{
                        "action": "export_metadata",
                        "description": "Xu·∫•t metadata ra file Excel",
                        "parameters": {{"file_ids": "dynamic", "output_format": "excel"}},
                        "order": 3
                    }}
                ],
                "expected_output": "Danh s√°ch file t√¨m ƒë∆∞·ª£c v·ªõi ph√¢n lo·∫°i v√† file Excel metadata",
                "estimated_steps": 3
            }}
            """
            
            # G·ªçi AI ƒë·ªÉ l√™n k·∫ø ho·∫°ch
            response = self.llm.invoke(prompt)
            plan_text = response.content.strip()
            
            # Parse JSON t·ª´ response
            try:
                # T√¨m JSON trong response
                start_idx = plan_text.find('{')
                end_idx = plan_text.rfind('}') + 1
                if start_idx != -1 and end_idx != -1:
                    plan_json = plan_text[start_idx:end_idx]
                    plan = json.loads(plan_json)
                else:
                    raise ValueError("Kh√¥ng t√¨m th·∫•y JSON trong response")
                    
            except json.JSONDecodeError:
                # Fallback: t·∫°o plan m·∫∑c ƒë·ªãnh
                plan = self._create_default_plan(user_request)
            
            return {
                'success': True,
                'plan': plan,
                'user_request': user_request,
                'created_at': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'plan': self._create_default_plan(user_request)
            }
    
    def _create_default_plan(self, user_request: str) -> Dict:
        """T·∫°o k·∫ø ho·∫°ch m·∫∑c ƒë·ªãnh khi AI kh√¥ng th·ªÉ parse"""
        return {
            "plan": [
                {
                    "action": "search_files",
                    "description": f"T√¨m ki·∫øm file theo y√™u c·∫ßu: {user_request}",
                    "parameters": {"query": user_request, "search_type": "both"},
                    "order": 1
                }
            ],
            "expected_output": "K·∫øt qu·∫£ t√¨m ki·∫øm file",
            "estimated_steps": 1
        }
    
    def execute_plan(self, plan: Dict, user_id: str, user_role: str) -> Dict:
        """Th·ª±c hi·ªán k·∫ø ho·∫°ch h√†nh ƒë·ªông"""
        try:
            execution_results = []
            current_files = []
            
            # S·∫Øp x·∫øp plan theo th·ª© t·ª±
            sorted_plan = sorted(plan['plan'], key=lambda x: x['order'])
            
            for step in sorted_plan:
                action = step['action']
                parameters = step['parameters']
                description = step['description']
                
                print(f"üîß Th·ª±c hi·ªán: {description}")
                
                # Th·ª±c hi·ªán t·ª´ng action
                if action == 'search_files':
                    result = self._execute_search_files(parameters, user_id, user_role)
                    current_files = result.get('files', [])
                    execution_results.append({
                        'step': step,
                        'result': result,
                        'status': 'success'
                    })
                
                elif action == 'classify_files':
                    # S·ª≠ d·ª•ng file_ids t·ª´ k·∫øt qu·∫£ search tr∆∞·ªõc ƒë√≥
                    if current_files:
                        file_ids = [f['id'] for f in current_files]
                        result = self._execute_classify_files(file_ids)
                        execution_results.append({
                            'step': step,
                            'result': result,
                            'status': 'success'
                        })
                
                elif action == 'extract_metadata':
                    if current_files:
                        file_ids = [f['id'] for f in current_files]
                        result = self._execute_extract_metadata(file_ids)
                        execution_results.append({
                            'step': step,
                            'result': result,
                            'status': 'success'
                        })
                
                elif action == 'export_metadata':
                    if current_files:
                        file_ids = [f['id'] for f in current_files]
                        result = self._execute_export_metadata(file_ids, parameters.get('output_format', 'excel'))
                        execution_results.append({
                            'step': step,
                            'result': result,
                            'status': 'success'
                        })
                
                elif action == 'upload_to_cloud':
                    if current_files:
                        file_ids = [f['id'] for f in current_files]
                        result = self._execute_upload_to_cloud(file_ids)
                        execution_results.append({
                            'step': step,
                            'result': result,
                            'status': 'success'
                        })
            
            # T·∫°o summary
            summary = self._create_execution_summary(execution_results, current_files)
            
            return {
                'success': True,
                'execution_results': execution_results,
                'summary': summary,
                'total_steps': len(execution_results),
                'completed_at': datetime.utcnow().isoformat()
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'execution_results': execution_results if 'execution_results' in locals() else []
            }
    
    def _execute_search_files(self, parameters: Dict, user_id: str, user_role: str) -> Dict:
        """Th·ª±c hi·ªán t√¨m ki·∫øm file"""
        query = parameters.get('query', '')
        search_type = parameters.get('search_type', 'both')
        
        results = file_search_engine.search_files(
            query=query,
            user_id=user_id,
            user_role=user_role,
            search_type=search_type,
            limit=10
        )
        
        return {
            'action': 'search_files',
            'query': query,
            'files_found': len(results),
            'files': results
        }
    
    def _execute_classify_files(self, file_ids: List[str]) -> Dict:
        """Th·ª±c hi·ªán ph√¢n lo·∫°i file"""
        classifications = []
        
        for file_id in file_ids:
            try:
                classification = file_classifier.get_file_classification(file_id)
                classifications.append({
                    'file_id': file_id,
                    'classification': classification
                })
            except Exception as e:
                classifications.append({
                    'file_id': file_id,
                    'error': str(e)
                })
        
        return {
            'action': 'classify_files',
            'total_files': len(file_ids),
            'classifications': classifications
        }
    
    def _execute_extract_metadata(self, file_ids: List[str]) -> Dict:
        """Th·ª±c hi·ªán tr√≠ch xu·∫•t metadata"""
        metadata_list = []
        
        for file_id in file_ids:
            try:
                file_info = file_manager.get_file_by_id(file_id)
                if file_info:
                    metadata = {
                        'file_id': file_id,
                        'filename': file_info.get('original_name', ''),
                        'file_type': file_info.get('file_type', ''),
                        'size': file_info.get('file_size', 0),
                        'uploaded_by': file_info.get('uploaded_by', ''),
                        'uploaded_at': file_info.get('uploaded_at', ''),
                        'classification': file_classifier.get_file_classification(file_id)
                    }
                    metadata_list.append(metadata)
            except Exception as e:
                metadata_list.append({
                    'file_id': file_id,
                    'error': str(e)
                })
        
        return {
            'action': 'extract_metadata',
            'total_files': len(file_ids),
            'metadata': metadata_list
        }
    
    def _execute_export_metadata(self, file_ids: List[str], output_format: str = 'excel') -> Dict:
        """Th·ª±c hi·ªán xu·∫•t metadata"""
        try:
            # L·∫•y metadata cho t·∫•t c·∫£ files
            metadata_list = []
            for file_id in file_ids:
                try:
                    file_info = file_manager.get_file_by_id(file_id)
                    if file_info:
                        classification = file_classifier.get_file_classification(file_id)
                        metadata = {
                            'File ID': file_id,
                            'T√™n file': file_info.get('original_name', ''),
                            'Lo·∫°i file': file_info.get('file_type', ''),
                            'K√≠ch th∆∞·ªõc (bytes)': file_info.get('file_size', 0),
                            'Ng∆∞·ªùi upload': file_info.get('uploaded_by', ''),
                            'Ng√†y upload': file_info.get('uploaded_at', ''),
                            'Nh√≥m': classification.get('group_name', ''),
                            'ƒê·ªô tin c·∫≠y': classification.get('confidence', 0),
                            'L√Ω do ph√¢n lo·∫°i': classification.get('reason', '')
                        }
                        metadata_list.append(metadata)
                except Exception as e:
                    metadata_list.append({
                        'File ID': file_id,
                        'L·ªói': str(e)
                    })
            
            # T·∫°o DataFrame v√† xu·∫•t Excel
            df = pd.DataFrame(metadata_list)
            
            # T·∫°o th∆∞ m·ª•c exports n·∫øu ch∆∞a c√≥
            exports_dir = 'uploads/exports'
            os.makedirs(exports_dir, exist_ok=True)
            
            # T·∫°o t√™n file
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f'metadata_export_{timestamp}.xlsx'
            filepath = os.path.join(exports_dir, filename)
            
            # Xu·∫•t Excel
            df.to_excel(filepath, index=False, engine='openpyxl')
            
            return {
                'action': 'export_metadata',
                'format': output_format,
                'filename': filename,
                'filepath': filepath,
                'total_records': len(metadata_list),
                'download_url': f'/api/files/download/export/{filename}'
            }
            
        except Exception as e:
            return {
                'action': 'export_metadata',
                'error': str(e)
            }
    
    def _execute_upload_to_cloud(self, file_ids: List[str]) -> Dict:
        """Th·ª±c hi·ªán upload metadata l√™n cloud"""
        upload_results = []
        
        for file_id in file_ids:
            try:
                file_info = file_manager.get_file_by_id(file_id)
                if file_info:
                    classification = file_classifier.get_file_classification(file_id)
                    cloud_result = cloud_integration.send_metadata_to_cloud(file_info, classification)
                    upload_results.append({
                        'file_id': file_id,
                        'success': True,
                        'cloud_result': cloud_result
                    })
                else:
                    upload_results.append({
                        'file_id': file_id,
                        'success': False,
                        'error': 'File not found'
                    })
            except Exception as e:
                upload_results.append({
                    'file_id': file_id,
                    'success': False,
                    'error': str(e)
                })
        
        return {
            'action': 'upload_to_cloud',
            'total_files': len(file_ids),
            'successful_uploads': len([r for r in upload_results if r['success']]),
            'failed_uploads': len([r for r in upload_results if not r['success']]),
            'results': upload_results
        }
    
    def _create_execution_summary(self, execution_results: List[Dict], files: List[Dict]) -> Dict:
        """T·∫°o summary c·ªßa qu√° tr√¨nh th·ª±c hi·ªán"""
        summary = {
            'total_steps_completed': len(execution_results),
            'files_processed': len(files),
            'actions_performed': []
        }
        
        for result in execution_results:
            step = result['step']
            action_result = result['result']
            
            summary['actions_performed'].append({
                'action': step['action'],
                'description': step['description'],
                'status': result['status'],
                'details': action_result
            })
        
        return summary

# Kh·ªüi t·∫°o instance
agentic_ai = AgenticAI() 